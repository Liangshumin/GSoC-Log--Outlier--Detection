,pattern_id,pattern
0,0,<*> is <*>
1,1,(EQUATOR) <*> kvi <*>
2,2,(RESET) equator <*> kv <*> kvi <*>
3,3,<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK
4,4,<*> currently is supported only on Linux.
5,5,<*> failures on node <*>
6,6,mapreduce.cluster.local.dir for child: <*>
7,7,<*> freed by <*> in <*>
8,8,<*> given a go for committing the task output.
9,9,"<*> is deprecated. Instead, use <*>"
10,10,<*> set in config null
11,11,<*> Task Transitioned from NEW to SCHEDULED
12,12,<*> Task Transitioned from RUNNING to SUCCEEDED
13,13,<*> Task Transitioned from SCHEDULED to RUNNING
14,14,<*> Task Transitioned from SUCCEEDED to SCHEDULED
15,15,<*> TaskAttempt Transitioned from ASSIGNED to RUNNING
16,16,<*> TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP
17,17,<*> TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
18,18,<*> TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
19,19,<*> TaskAttempt Transitioned from NEW to UNASSIGNED
20,20,<*> TaskAttempt Transitioned from NEW to KILLED
21,21,<*> TaskAttempt Transitioned from NEW to FAILED
22,22,<*> TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
23,23,<*> TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP
24,24,<*> TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
25,25,<*> TaskAttempt Transitioned from RUNNING to KILLED
26,26,<*> TaskAttempt Transitioned from SUCCEEDED to KILLED
27,27,<*> TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
28,28,<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
29,29,<*> TaskAttempt Transitioned from UNASSIGNED to KILLED
30,30,<*> TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
31,31,<*> TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
32,32,<*> TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
33,33,<*> Thread started: EventFetcher for fetching Map Completion Events
34,34,<*> Transitioned from COMMITTING to SUCCEEDED
35,35,<*> Transitioned from INITED to SETUP
36,36,<*> Transitioned from NEW to INITED
37,37,<*> Transitioned from NEW to SUCCEEDED
38,38,<*> Transitioned from RUNNING to COMMITTING
39,39,<*> Transitioned from RUNNING to ERROR
40,40,<*> Transitioned from RUNNING to REBOOT
41,41,<*> Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
42,42,<*> Transitioned from SETUP to RUNNING
43,43,<*>: Got <*> new map-outputs
44,44,<*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)
45,45,Abandoning <*>
46,46,Added <*> to list of failed maps
47,47,Added filter AM_PROXY_FILTER (class=<*>) to context mapreduce
48,48,Added filter AM_PROXY_FILTER (class=<*>) to context static
49,49,Added global filter 'safety' (class=<*>)
50,50,Adding <*> tokens and <*> secret keys for NM use for launching container
51,51,Adding job token for <*> to <*>
52,52,adding path spec: <*>
53,53,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
54,54,Address change detected. Old: <*> New: <*>
55,55,After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
56,56,All maps assigned. Ramping up all remaining reduces:<*>
57,57,assigned <*> of <*> to <*> to <*>
58,58,Assigned container <*> to <*>
59,59,Assigned from earlierFailedMaps
60,60,Assigned to reduce
61,61,Assigning <*> with <*> to <*>
62,62,"Assigning container Container: [ContainerId: <*>, NodeId: <*>, NodeHttpAddress: <*> Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>}, ] to fast fail map"
63,63,ATTEMPT_START <*>
64,64,Auth successful for <*> (auth:SIMPLE)
65,65,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
66,66,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:0 ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
67,67,blacklistDisablePercent is <*>
68,68,bufstart = <*>; bufvoid = <*>
69,69,bufstart = <*>; bufend = <*>; bufvoid = <*>
70,70,Calling handler for JobFinishedEvent
71,71,Calling stop for all the services
72,72,"Cannot assign container Container: [ContainerId: <*>, NodeId: <*>, NodeHttpAddress: <*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: <*>, service: <*> }, ] for a map as either  container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true"
73,73,cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
74,74,Commit go/no-go request from <*>
75,75,Commit-pending state update from <*>
76,76,"Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>""; destination host is: <*>;"
77,77,Communication exception: java.net.ConnectException: Call From <*> to <*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <*>
78,78,Communication exception: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
79,79,"completedMapPercent <*> totalResourceLimit:<memory:<*>, vCores:<*>> finalMapResourceLimit:<memory:<*>, vCores:<*>> finalReduceResourceLimit:<memory:<*>, vCores:<*>> netScheduledMapResource:<memory:<*>, vCores:<*>> netScheduledReduceResource:<memory:<*>, vCores:<*>>"
80,80,Connecting to ResourceManager at <*>
81,81,Connection retry failed with <*> attempts in <*> seconds
82,82,Container complete event for unknown container id <*>
83,83,Copied to done location: <*>
84,84,Copying <*> to <*>
85,85,Could not contact RM after <*> milliseconds.
86,86,Could not delete <*>
87,87,"Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [<*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*>. Will get new block locations from namenode and retry..."
88,88,Could not parse the old history file. Will not have old AMinfos
89,89,Created <*> for application <*>
90,90,DataStreamer Exception
91,91,Default file system [<*>]
92,92,DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>
93,93,Deleting staging directory <*>
94,94,"DFS chooseDataNode: got # <*> IOException, will wait for <*>."
95,95,DFS Read
96,96,Diagnostics report from <*>: AttemptID:<*> Timed out after <*> secs
97,97,Diagnostics report from <*>: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
98,98,Diagnostics report from <*>: Container killed by the ApplicationMaster.
99,99,Diagnostics report from <*>: Container released on a *lost* node
100,100,Diagnostics report from <*>: Error: java.io.IOException: Spill failed
101,101,Diagnostics report from <*>: Error: java.io.IOException: There is not enough space on the disk
102,102,Diagnostics report from <*>: Error: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
103,103,Diagnostics report from <*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
104,104,Diagnostics report from <*>: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>
105,105,Diagnostics report from <*>: FSError: java.io.IOException: There is not enough space on the disk
106,106,Diagnostics report from <*>:
107,107,Done acknowledgement from <*>
108,108,"Down to the last merge-pass, with <*> segments left of total size: <*>"
109,109,Emitting job history data to the timeline server is not enabled
110,110,Error closing writer for JobID: <*>
111,111,Error communicating with RM: Could not contact RM after <*> milliseconds.
112,112,Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>
113,113,ERROR IN CONTACTING RM.
114,114,Error writing History Event: <*>
115,115,"Event Writer setup for JobId: <*>, File: <*>"
116,116,EventFetcher is interrupted.. Returning
117,117,Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
118,118,Exception in createBlockOutputStream
119,119,Exception in getting events
120,120,Exception running child : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
121,121,Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>
122,122,Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>
123,123,Exception while unregistering
124,124,Excluding datanode <*>
125,125,Executing with tokens:
126,126,Extract <*> to <*>
127,127,"Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information"
128,128,"Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information"
129,129,"Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information"
130,130,Failed to connect to <*> with <*> map outputs
131,131,"Failure sending status update: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>""; destination host is: <*>;"
132,132,Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
133,133,finalMerge called with <*> in-memory map-outputs and <*> on-disk map-outputs
134,134,Finished spill <*>
135,135,for url=<*>?job=<*>&reduce=<*>&map=<*> sent hash and received reply
136,136,Found jobId <*> to have not been closed. Will close
137,137,"getResources() for <*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*>> knownNMs=<*>"
138,138,Going to preempt <*> due to lack of space for maps
139,139,Got allocated containers <*>
140,140,Graceful stop failed
141,141,History url is <*>
142,142,Http request log for http.requests.mapreduce is not defined
143,143,I/O error constructing remote block reader.
144,144,Ignoring exception during close for <*>
145,145,Ignoring obsolete output of FAILED map-task: <*>
146,146,Ignoring obsolete output of KILLED map-task: <*>
147,147,Ignoring obsolete output of OBSOLETE map-task: <*>
148,148,"In stop, writing event JOB_FINISHED"
149,149,"In stop, writing event MAP_ATTEMPT_FAILED"
150,150,"In stop, writing event TASK_FINISHED"
151,151,Input size for job <*> = <*> Number of splits = <*>
152,152,Instantiated MRClientService at <*>
153,153,IPC Server handler <*> on <*> caught an exception
154,154,"IPC Server handler <*> on <*>, call statusUpdate(<*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*> Call#<*> Retry#<*>: output error"
155,155,IPC Server listener on <*>: starting
156,156,IPC Server Responder: starting
157,157,Issuing kill to other attempt <*>
158,158,Jetty bound to port <*>
159,159,jetty-6.1.26
160,160,JOB_CREATE <*>
161,161,JobHistoryEventHandler notified that forceJobCompletion is false
162,162,JobHistoryEventHandler notified that forceJobCompletion is true
163,163,JVM with ID : <*> asked for a task
164,164,JVM with ID: <*> given task: <*>
165,165,KILLING <*>
166,166,Killing taskAttempt:<*> because it is running on unusable node:<*>
167,167,"Kind: <*>, Service: <*>, Ident: (<*>)"
168,168,kvstart = <*>; length = <*>
169,169,kvstart = <*>; kvend = <*>; length = <*>
170,170,"Last retry, killing <*>"
171,171,Launching <*>
172,172,loaded properties from <*>
173,173,Logging to <*> via <*>
174,174,Map output collector class = <*>
175,175,MapCompletionEvents <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
176,176,MapCompletionEvents request from <*> startIndex <*> maxEvents <*>
177,177,mapreduce.task.io.sort.mb: <*>
178,178,"mapResourceRequest:<memory:<*>, vCores:<*>>"
179,179,MapTask metrics system shutdown complete.
180,180,MapTask metrics system started
181,181,MapTask metrics system stopped.
182,182,"maxContainerCapability: <memory:<*>, vCores:<*>>"
183,183,maxTaskFailuresPerNode is <*>
184,184,"MergerManager: memoryLimit=<*>, maxSingleShuffleLimit=<*>, mergeThreshold=<*>, ioSortFactor=<*>, memToMemMergeOutputsThreshold=<*>"
185,185,"Merging <*> files, <*> from disk"
186,186,Merging <*> intermediate segments out of a total of <*>
187,187,"Merging <*> segments, <*> from memory into reduce"
188,188,Merging <*> sorted segments
189,189,Moved tmp to done: <*>
190,190,"MRAppMaster launching normal, non-uberized, multi-container job <*>"
191,191,MRAppMaster metrics system started
192,192,nodeBlacklistingEnabled:true
193,193,Not uberizing <*> because: not enabled; too many maps; too much input;
194,194,Notify <*> isAMLastRetry: <*>
195,195,Notify JHEH isAMLastRetry: true
196,196,Notify RMCommunicator isAMLastRetry: true
197,197,Num completed Tasks: <*>
198,198,Number of reduces for job <*> = <*>
199,199,Opening proxy : <*>
200,200,Preempting <*>
201,201,Previous history file is at <*>
202,202,Process Thread Dump: Communication exception
203,203,Processing split: <*>
204,204,Processing the event EventType: <*> for container <*> taskAttempt <*>
205,205,Processing the event EventType: CONTAINER_DEALLOCATE
206,206,Processing the event EventType: JOB_COMMIT
207,207,Processing the event EventType: JOB_SETUP
208,208,Processing the event EventType: TASK_ABORT
209,209,Progress of TaskAttempt <*> is : <*>
210,210,Putting shuffle token in serviceData
211,211,queue: default
212,212,Ramping down all scheduled reduces:<*>
213,213,Ramping up <*>
214,214,Read <*> bytes from map-output for <*>
215,215,Read completed tasks from history <*>
216,216,Read from history task <*>
217,217,"Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"
218,218,Received completed container <*>
219,219,"Recovering task <*> from prior app attempt, status was <*>"
220,220,Recovery is enabled. Will try to recover from previous life on best effort basis.
221,221,Reduce preemption successful <*>
222,222,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>
223,223,Reduce slow start threshold reached. Scheduling reduces.
224,224,"reduceResourceRequest:<memory:<*>, vCores:<*>>"
225,225,ReduceTask metrics system shutdown complete.
226,226,ReduceTask metrics system started
227,227,ReduceTask metrics system stopped.
228,228,Registered webapp guice modules
229,229,Registering class <*> for class <*>
230,230,"Releasing unassigned and invalid container Container: [ContainerId: <*>, NodeId: <*>, NodeHttpAddress: <*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*> }, ]. RM may have assignment issues"
231,231,Reporting fetch failure for <*> to jobtracker.
232,232,Resolved <*> to <*>
233,233,Result of canCommit for <*>
234,234,Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>
235,235,"Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)"
236,236,RMCommunicator notified that shouldUnregistered is: false
237,237,RMCommunicator notified that shouldUnregistered is: true
238,238,Runnning cleanup for the task
239,239,Saved output of task <*> to <*>
240,240,Scheduled snapshot period at <*> second(s).
241,241,Scheduling a redundant attempt for task <*>
242,242,Service <*> failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
243,243,Service <*> failed in state STOPPED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
244,244,Service <*> failed in state STOPPED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
245,245,Setting job diagnostics to
246,246,Shuffle failed : local error on this node: <*>
247,247,Shuffle port returned by ContainerManager for <*> : <*>
248,248,Size of containertokens_dob is <*>
249,249,Skipping cleaning up the staging dir. assuming AM will be retried.
250,250,Sleeping for <*> before retrying again. Got null now.
251,251,Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]
252,252,soft limit at <*>
253,253,Spilling map output
254,254,Started <*>
255,255,Starting flush of map output
256,256,Starting Socket Reader <*> for port <*>
257,257,Stopped JobHistoryEventHandler. super.stop()
258,258,Stopping IPC Server listener on <*>
259,259,Stopping IPC Server Responder
260,260,Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>
261,261,Stopping MapTask metrics system...
262,262,Stopping ReduceTask metrics system...
263,263,Stopping server on <*>
264,264,Successfully connected to <*> for <*>
265,265,Task <*> done.
266,266,Task <*> failed : org.apache.hadoop.fs.FSError: java.io.IOException: There is not enough space on the disk
267,267,Task <*> is allowed to commit now
268,268,Task cleanup failed for attempt <*>
269,269,Task succeeded with attempt <*>
270,270,Task: <*> - exited : java.io.IOException: Spill failed
271,271,Task: <*> - exited : java.io.IOException: There is not enough space on the disk
272,272,Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
273,273,Task: <*> - exited : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
274,274,Task: <*> - exited : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>
275,275,Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk
276,276,Task:<*> is done. And is in the process of committing
277,277,TaskAttempt killed because it ran on unusable node <*> AttemptId:<*>
278,278,TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]
279,279,TaskHeartbeatHandler thread interrupted
280,280,The job-conf file on the remote FS is <*>
281,281,The job-jar file on the remote FS is <*>
282,282,Thread Thread[<*>] threw an Exception.
283,283,"Unable to parse prior job history, aborting recovery"
284,284,Upper limit on the thread pool size is <*>
285,285,Using callQueue class java.util.concurrent.LinkedBlockingQueue
286,286,Using mapred <*>
287,287, Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>
288,288,Using ShuffleConsumerPlugin: <*>
289,289,Waiting for application to be successfully unregistered.
290,290,We are finishing cleanly so this is the last retry
291,291,We launched <*> speculations.  Sleeping <*> milliseconds.
292,292,Web app <*> started at <*>
293,293,When stopping the service JobHistoryEventHandler : org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
294,294,When stopping the service JobHistoryEventHandler : org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
295,295,When stopping the service JobHistoryEventHandler : org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
296,296,yarn.client.max-cached-nodemanagers-proxies : <*>
